{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-09T15:10:25.410967Z",
     "start_time": "2024-12-09T15:10:25.391816Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Load the datasets\n",
    "awards_players_df = pd.read_csv('../dataset/awards_players.csv')\n",
    "coaches_df = pd.read_csv('../dataset/coaches.csv')\n",
    "players_df = pd.read_csv('../dataset/players.csv')\n",
    "players_teams_df = pd.read_csv('../dataset/players_teams.csv')\n",
    "series_post_df = pd.read_csv('../dataset/series_post.csv')\n",
    "teams_df = pd.read_csv('../dataset/teams.csv')\n",
    "teams_post_df = pd.read_csv('../dataset/teams_post.csv')\n",
    "\n",
    "# Remove useless columns from the datasets\n",
    "awards_players_df = awards_players_df.drop(columns=['lgID'])\n",
    "players_df = players_df.drop(columns=['firstseason', 'lastseason', 'deathDate'])\n",
    "coaches_df = coaches_df.drop(columns=['lgID'])\n",
    "series_post_df = series_post_df.drop(columns=['lgIDLoser', 'lgIDWinner'])\n",
    "teams_post_df = teams_post_df.drop(columns=['lgID'])\n",
    "teams_df = teams_df.drop(\n",
    "    columns=['lgID', 'divID', 'seeded', 'tmORB', 'tmDRB', 'tmTRB', 'opptmORB', 'opptmDRB', 'opptmTRB'])\n",
    "players_teams_df = players_teams_df.drop(columns=['lgID'])"
   ],
   "outputs": [],
   "execution_count": 209
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T15:10:25.445928Z",
     "start_time": "2024-12-09T15:10:25.438590Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Merge players, teams, and awards data\n",
    "players_teams_merged = pd.merge(players_df, players_teams_df, left_on='bioID', right_on='playerID')\n",
    "players_teams_awards = pd.merge(players_teams_merged, awards_players_df, on=['year', 'playerID'], how='left')\n",
    "\n",
    "#remove pos, height, weight, college, collegeOther, birthDate, playerID, GP and GS\n",
    "players_teams_awards = players_teams_awards.drop(\n",
    "    columns=['pos', 'height', 'weight', 'college', 'collegeOther', 'birthDate', 'playerID', 'GP', 'GS', 'PostGP', 'PostGS'])\n"
   ],
   "id": "80171f90bfca7281",
   "outputs": [],
   "execution_count": 210
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T15:10:25.496456Z",
     "start_time": "2024-12-09T15:10:25.486123Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define award scores\n",
    "award_scores = {\n",
    "    'All-Star Game Most Valuable Player': 7,\n",
    "    'Coach of the Year': 10,\n",
    "    'Defensive Player of the Year': 7,\n",
    "    'Kim Perrot Sportsmanship Award': 0,\n",
    "    'Most Improved Player': 5,\n",
    "    'Most Valuable Player': 10,\n",
    "    'Rookie of the Year': 5,\n",
    "    'Sixth Woman of the Year': 6,\n",
    "    'WNBA Finals Most Valuable Player': 8,\n",
    "    'WNBA All-Decade Team': 6,\n",
    "    'WNBA All Decade Team Honorable Mention': 4\n",
    "}\n",
    "\n",
    "# Map the award scores to the dataframe\n",
    "players_teams_awards['award_score'] = players_teams_awards['award'].map(award_scores).fillna(0)\n",
    "\n",
    "# drop award column\n",
    "players_teams_awards = players_teams_awards.drop(columns=['award'])\n",
    "\n",
    "# List of columns to group by (excluding 'award_score')\n",
    "columns_to_group_by = ['bioID', 'year', 'stint']\n",
    "\n",
    "# Group by the columns and aggregate\n",
    "players_teams_awards = players_teams_awards.groupby(columns_to_group_by).agg({\n",
    "    'award_score': 'sum',  # Sum award scores\n",
    "    **{col: 'first' for col in players_teams_awards.columns if col not in columns_to_group_by + ['award_score']}\n",
    "}).reset_index()"
   ],
   "id": "7d44721cf4b465d2",
   "outputs": [],
   "execution_count": 211
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T15:10:25.600682Z",
     "start_time": "2024-12-09T15:10:25.534265Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define coefficients for player statistics\n",
    "coefficients = {\n",
    "    'minutes': 0.2,\n",
    "    'points': 0.45,\n",
    "    'oRebounds': 0.1,\n",
    "    'dRebounds': 0.1,\n",
    "    'rebounds': 0.15,\n",
    "    'assists': 0.25,\n",
    "    'steals': 0.2,\n",
    "    'blocks': 0.35,\n",
    "    'turnovers': -0.3,  # Negative coefficient for turnovers\n",
    "    'PF': 0.1,\n",
    "    'fgAttempted': 0.05,\n",
    "    'fgMade': 0.1,\n",
    "    'ftAttempted': 0.1,\n",
    "    'ftMade': 0.2,\n",
    "    'threeAttempted': 0.15,\n",
    "    'threeMade': 0.25,\n",
    "    'dq': -0.4  # Negative coefficient for dq\n",
    "}\n",
    "\n",
    "# List of columns to be used in the weighted sum calculation\n",
    "columns_to_use = list(coefficients.keys())\n",
    "\n",
    "\n",
    "# Function to calculate the weighted sum based on coefficients\n",
    "def calculate_weighted_sum(row):\n",
    "    total = 0\n",
    "    for col in columns_to_use:\n",
    "        total += row[col] * coefficients[col]\n",
    "    return total\n",
    "\n",
    "\n",
    "# Apply the function to calculate the weighted sum and store it in a new column\n",
    "players_teams_awards['weighted_score'] = players_teams_awards.apply(calculate_weighted_sum, axis=1)\n",
    "\n",
    "# Define coefficients for post-season statistics\n",
    "post_coefficients = {\n",
    "    'PostMinutes': 0.2,\n",
    "    'PostPoints': 0.45,\n",
    "    'PostoRebounds': 0.1,\n",
    "    'PostdRebounds': 0.1,\n",
    "    'PostRebounds': 0.15,\n",
    "    'PostAssists': 0.25,\n",
    "    'PostSteals': 0.2,\n",
    "    'PostBlocks': 0.35,\n",
    "    'PostTurnovers': -0.3,  # Negative coefficient for turnovers\n",
    "    'PostPF': 0.1,\n",
    "    'PostfgAttempted': 0.05,\n",
    "    'PostfgMade': 0.1,\n",
    "    'PostftAttempted': 0.1,\n",
    "    'PostftMade': 0.2,\n",
    "    'PostthreeAttempted': 0.15,\n",
    "    'PostthreeMade': 0.25,\n",
    "    'PostDQ': -0.4  # Negative coefficient for dq\n",
    "}\n",
    "\n",
    "# List of 'Post' columns to be used in the weighted sum calculation\n",
    "post_columns_to_use = list(post_coefficients.keys())\n",
    "\n",
    "\n",
    "# Function to calculate the weighted sum based on 'Post' coefficients\n",
    "def calculate_post_weighted_sum(row):\n",
    "    total = 0\n",
    "    for col in post_columns_to_use:\n",
    "        total += row[col] * post_coefficients[col]\n",
    "    return total\n",
    "\n",
    "\n",
    "# Apply the function to calculate the post-season weighted sum and store it in a new column\n",
    "players_teams_awards['post_weighted_score'] = players_teams_awards.apply(calculate_post_weighted_sum, axis=1)\n",
    "\n",
    "# Remove the individual columns used in the calculation\n",
    "players_teams_awards.drop(columns=columns_to_use, inplace=True)\n",
    "\n",
    "# Remove the individual 'Post' columns used in the calculation\n",
    "players_teams_awards.drop(columns=post_columns_to_use, inplace=True)\n",
    "\n",
    "# add the franchID column to the players_teams_awards (check the tmID and year and add it)\n",
    "players_teams_awards = pd.merge(players_teams_awards, teams_df[['year', 'tmID', 'franchID']], on=['year', 'tmID'], how='left')"
   ],
   "id": "e83510449d90487e",
   "outputs": [],
   "execution_count": 212
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T15:10:25.633145Z",
     "start_time": "2024-12-09T15:10:25.630347Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# create a clean_teams df that only has year, tmID, franchID, and playoff, and map Y to 1 and N to 0 in playoff\n",
    "clean_teams = teams_df[['year', 'tmID', 'confID', 'playoff']].copy()\n",
    "clean_teams['playoff'] = clean_teams['playoff'].map({'Y': 1, 'N': 0})"
   ],
   "id": "f7ffcfbbe5d0ff68",
   "outputs": [],
   "execution_count": 213
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T15:10:26.004140Z",
     "start_time": "2024-12-09T15:10:25.672721Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# look at tmID to calculate the columns of the team statistics when merging with players_teams_awards, but look at the franchID to compare the rolling average of the team statistics\n",
    "\n",
    "def calculate_rolling_features(df, columns, window=3):\n",
    "    \"\"\"\n",
    "    Calculates rolling average features for the given columns in the dataframe,\n",
    "    handling duplicates and considering 'stint' as part of the aggregation.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Input dataframe.\n",
    "        columns (list of str): List of column names to calculate rolling features for.\n",
    "        window (int): Rolling window size. Default is 3.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Dataframe with added rolling features, including tmID and franchID.\n",
    "    \"\"\"\n",
    "    # Keep tmID and franchID for merging later\n",
    "    id_columns = ['bioID', 'year', 'tmID', 'franchID']\n",
    "\n",
    "    # Aggregate duplicate rows for the same bioID, year pair\n",
    "    aggregated_df = (\n",
    "        df.groupby(['bioID', 'year'])[columns]\n",
    "        .sum()  # Sum scores across stints\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    # Add tmID and franchID back after aggregating\n",
    "    unique_id_data = df[id_columns].drop_duplicates(subset=['bioID', 'year'])\n",
    "    aggregated_df = aggregated_df.merge(unique_id_data, on=['bioID', 'year'], how='left')\n",
    "\n",
    "    # Sort by bioID and year\n",
    "    aggregated_df = aggregated_df.sort_values(['bioID', 'year']).copy()\n",
    "\n",
    "    for col in columns:\n",
    "        rolling_col_name = f'{col}_rolling_{window}'\n",
    "\n",
    "        def rolling_avg(group):\n",
    "            values = group.shift(1)  # Exclude current season by shifting\n",
    "            filtered = values.replace(0, np.nan)  # Replace zeros with NaN\n",
    "            return (\n",
    "                filtered.rolling(window=window, min_periods=1)\n",
    "                .mean()  # Calculate rolling mean, ignoring NaN\n",
    "            )\n",
    "\n",
    "        aggregated_df[rolling_col_name] = (\n",
    "            aggregated_df.groupby('bioID')[col]\n",
    "            .apply(rolling_avg)\n",
    "            .reset_index(level=0, drop=True)  # Align index with aggregated_df\n",
    "        )\n",
    "\n",
    "    return aggregated_df\n",
    "\n",
    "# Columns to calculate rolling features for\n",
    "rolling_columns = ['award_score', 'weighted_score', 'post_weighted_score']\n",
    "\n",
    "player_rolling_features = calculate_rolling_features(\n",
    "    players_teams_awards,\n",
    "    columns=rolling_columns\n",
    ")\n",
    "\n",
    "# replace NaN values with 0\n",
    "player_rolling_features = player_rolling_features.fillna(0)\n",
    "\n",
    "# Merge with clean_teams on year and tmID\n",
    "merged_df = pd.merge(clean_teams, player_rolling_features, on=['year', 'tmID'], how='left')\n",
    "\n",
    "# Aggregate team-level statistics by year and tmID\n",
    "teams_with_rolling_aggregated = merged_df.groupby(['year', 'tmID'], as_index=False).agg({\n",
    "    'franchID': 'first',  # Keep the first franchID\n",
    "    'playoff': 'first',   # Keep the first playoff value\n",
    "    'confID': 'first',\n",
    "    'award_score_rolling_3': 'sum',\n",
    "    'weighted_score_rolling_3': 'sum',\n",
    "    'post_weighted_score_rolling_3': 'sum'\n",
    "})\n"
   ],
   "id": "3d28c5a4e0e85201",
   "outputs": [],
   "execution_count": 214
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T15:10:26.040487Z",
     "start_time": "2024-12-09T15:10:26.035241Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define the rolling columns for features\n",
    "rolling_columns_aggregated = [\n",
    "    'award_score_rolling_3',\n",
    "    'weighted_score_rolling_3',\n",
    "    'post_weighted_score_rolling_3'\n",
    "]\n",
    "\n",
    "# Filter data for training and testing\n",
    "train_data = teams_with_rolling_aggregated[\n",
    "    (teams_with_rolling_aggregated['year'] >= 4) & (teams_with_rolling_aggregated['year'] <= 8)\n",
    "    ]\n",
    "test_data = teams_with_rolling_aggregated[teams_with_rolling_aggregated['year'] >= 9]\n",
    "\n",
    "# Prepare features and labels\n",
    "X_train = train_data[rolling_columns_aggregated].fillna(0)\n",
    "y_train = train_data['playoff']\n",
    "\n",
    "X_test = test_data[rolling_columns_aggregated].fillna(0)\n",
    "y_test = test_data['playoff']\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Handle any NaN values (if necessary)\n",
    "X_train = X_train.fillna(0)\n",
    "X_test = X_test.fillna(0)"
   ],
   "id": "3d67736bad516c3e",
   "outputs": [],
   "execution_count": 215
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T15:10:26.079251Z",
     "start_time": "2024-12-09T15:10:26.077525Z"
    }
   },
   "cell_type": "code",
   "source": "PLAYOFF_SPOTS = 8",
   "id": "61e2969eaf87194b",
   "outputs": [],
   "execution_count": 216
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T15:10:26.201961Z",
     "start_time": "2024-12-09T15:10:26.126325Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Train a Gradient Boosting Classifier as an example\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict probabilities instead of direct class labels\n",
    "y_proba = clf.predict_proba(X_test)[:, 1]  # Probability of being class 1 (making playoffs)\n",
    "\n",
    "# Create a copy of the test dataset including identifiers\n",
    "predictions = test_data[['year', 'tmID', 'franchID', 'confID']].copy()  # Include 'year', 'tmID', and 'franchID'\n",
    "predictions[rolling_columns_aggregated] = X_test  # Add the rolling features\n",
    "\n",
    "# Add probabilities and true labels\n",
    "predictions['proba'] = y_proba  # Predicted probabilities\n",
    "predictions['true_label'] = y_test.values  # True labels\n",
    "\n",
    "# Sort by year, confID, and probability, descending\n",
    "predictions = predictions.sort_values(by=['year', 'confID', 'proba'], ascending=[True, True, False])\n",
    "\n",
    "# Apply playoff cutoff per conference and year\n",
    "final_predictions = []\n",
    "PLAYOFF_SPOTS_PER_CONF = 4\n",
    "\n",
    "for (year, confID), group in predictions.groupby(['year', 'confID']):\n",
    "    group['playoff_pred'] = 0  # Default to not making playoffs\n",
    "    group.loc[group.head(PLAYOFF_SPOTS_PER_CONF).index, 'playoff_pred'] = 1  # Top 4 in each conference\n",
    "    final_predictions.append(group)\n",
    "\n",
    "# Combine results\n",
    "final_predictions = pd.concat(final_predictions)\n",
    "\n",
    "# Ensure output is ordered by year and franchise ID\n",
    "final_predictions = final_predictions.sort_values(by=['year', 'franchID'])\n",
    "\n",
    "# Generate list of playoff predictions per year\n",
    "playoff_output = final_predictions.groupby('year')['playoff_pred'].apply(list)\n",
    "\n",
    "# Example output for year 9\n",
    "print(playoff_output[9])  # List of 0s and 1s for each team in year 9\n",
    "\n",
    "# Extract predictions and true labels\n",
    "y_pred_final = final_predictions['playoff_pred']\n",
    "y_true_final = final_predictions['true_label']\n",
    "\n",
    "# Evaluate performance\n",
    "print(\"Precision:\", precision_score(y_true_final, y_pred_final))\n",
    "print(\"Recall:\", recall_score(y_true_final, y_pred_final))\n",
    "print(\"Accuracy:\", accuracy_score(y_true_final, y_pred_final))\n",
    "print(\"F1 Score:\", f1_score(y_true_final, y_pred_final))\n",
    "print(classification_report(y_true_final, y_pred_final))"
   ],
   "id": "67f742d27d305b32",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1]\n",
      "Precision: 0.75\n",
      "Recall: 0.75\n",
      "Accuracy: 0.7037037037037037\n",
      "F1 Score: 0.75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.64      0.64        11\n",
      "           1       0.75      0.75      0.75        16\n",
      "\n",
      "    accuracy                           0.70        27\n",
      "   macro avg       0.69      0.69      0.69        27\n",
      "weighted avg       0.70      0.70      0.70        27\n",
      "\n"
     ]
    }
   ],
   "execution_count": 217
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T15:10:26.363500Z",
     "start_time": "2024-12-09T15:10:26.230538Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Import the season 11 data\n",
    "teams_df_11 = pd.read_csv('../dataset/Season_11/teams.csv')\n",
    "players_df_11 = pd.read_csv('../dataset/Season_11/players_teams.csv')\n",
    "coaches_df_11 = pd.read_csv('../dataset/Season_11/coaches.csv')\n",
    "\n",
    "#drop columns\n",
    "teams_df_11 = teams_df_11.drop(columns=['lgID', 'name', 'arena'])\n",
    "coaches_df_11 = coaches_df_11.drop(columns=['lgID', 'stint'])\n",
    "players_df_11 = players_df_11.drop(columns=['lgID', 'stint'])\n",
    "\n",
    "# for each player, look for their bioID in player_rolling_features and add the weighted_score, award_score, and post_weighted_score for years 8, 9, and 10. If the player is not found, add 0 for all three columns, and if the player is found but the year is not found, add 0 for the missing year(s).\n",
    "\n",
    "rolling_years = [8, 9, 10]\n",
    "\n",
    "# Initialize new columns in players_df_11 with float64 data type\n",
    "for year in rolling_years:\n",
    "    players_df_11[f'weighted_score_y{year}'] = 0.0\n",
    "    players_df_11[f'award_score_y{year}'] = 0.0\n",
    "    players_df_11[f'post_weighted_score_y{year}'] = 0.0\n",
    "\n",
    "# Iterate over each row in players_df_11\n",
    "for index, row in players_df_11.iterrows():\n",
    "    bioID = row['playerID']\n",
    "\n",
    "    # Filter player_rolling_features for the current player\n",
    "    player_data = player_rolling_features[player_rolling_features['bioID'] == bioID]\n",
    "\n",
    "    # For each rolling year, fetch scores or assign 0 if not available\n",
    "    for year in rolling_years:\n",
    "        year_data = player_data[player_data['year'] == year]\n",
    "        if not year_data.empty:\n",
    "            players_df_11.at[index, f'weighted_score_y{year}'] = float(year_data['weighted_score'].iloc[0])\n",
    "            players_df_11.at[index, f'award_score_y{year}'] = float(year_data['award_score'].iloc[0])\n",
    "            players_df_11.at[index, f'post_weighted_score_y{year}'] = float(year_data['post_weighted_score'].iloc[0])\n",
    "\n",
    "# Print the updated DataFrame for verification\n",
    "print(players_df_11.head())\n",
    "\n",
    "def calculate_player_rolling_features11(df):\n",
    "    \"\"\"\n",
    "    Calculates the 3-year average of weighted_score, award_score, and post_weighted_score\n",
    "    for each player across years 8, 9, and 10.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Input DataFrame with columns:\n",
    "            - playerID\n",
    "            - year\n",
    "            - tmID\n",
    "            - weighted_score_y8, award_score_y8, post_weighted_score_y8\n",
    "            - weighted_score_y9, award_score_y9, post_weighted_score_y9\n",
    "            - weighted_score_y10, award_score_y10, post_weighted_score_y10\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with added rolling average columns:\n",
    "            - weighted_score_rolling_3\n",
    "            - award_score_rolling_3\n",
    "            - post_weighted_score_rolling_3\n",
    "    \"\"\"\n",
    "    # List of the years to include in the rolling calculation\n",
    "    rolling_years = [8, 9, 10]\n",
    "\n",
    "    # Initialize rolling columns\n",
    "    df['weighted_score_rolling_3'] = 0.0\n",
    "    df['award_score_rolling_3'] = 0.0\n",
    "    df['post_weighted_score_rolling_3'] = 0.0\n",
    "\n",
    "    # Calculate the rolling averages\n",
    "    for index, row in df.iterrows():\n",
    "        scores = {\n",
    "            'weighted_score': [],\n",
    "            'award_score': [],\n",
    "            'post_weighted_score': []\n",
    "        }\n",
    "\n",
    "        # Collect scores for years 8, 9, and 10\n",
    "        for year in rolling_years:\n",
    "            for key in scores.keys():\n",
    "                column_name = f'{key}_y{year}'\n",
    "                if column_name in df.columns:\n",
    "                    scores[key].append(row[column_name])\n",
    "\n",
    "        # Calculate the averages ignoring zeros\n",
    "        for key, values in scores.items():\n",
    "            rolling_avg = (\n",
    "                sum(value for value in values if value != 0) / len(values)\n",
    "                if any(value != 0 for value in values)\n",
    "                else 0\n",
    "            )\n",
    "            df.at[index, f'{key}_rolling_3'] = rolling_avg\n",
    "\n",
    "    return df\n",
    "\n",
    "# Calculate rolling features for players_df_11\n",
    "players_df_11 = calculate_player_rolling_features11(players_df_11)\n",
    "\n",
    "#drop old columns\n",
    "players_df_11 = players_df_11.drop(columns=[\n",
    "    'weighted_score_y8', 'award_score_y8', 'post_weighted_score_y8',\n",
    "    'weighted_score_y9', 'award_score_y9', 'post_weighted_score_y9',\n",
    "    'weighted_score_y10', 'award_score_y10', 'post_weighted_score_y10'\n",
    "])\n",
    "\n",
    "# Print the updated DataFrame for verification\n",
    "print(players_df_11.head())"
   ],
   "id": "da1541c54a8e4225",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     playerID  year tmID  weighted_score_y8  award_score_y8  \\\n",
      "0  adairje01w    11  MIN            0.00000         0.00000   \n",
      "1  adamsda01w    11  SAS            0.00000         0.00000   \n",
      "2  ajavoma01w    11  WAS            0.00000         0.00000   \n",
      "3  anosini01w    11  WAS            0.00000         0.00000   \n",
      "4  appelja01w    11  SAS            0.00000         0.00000   \n",
      "\n",
      "   post_weighted_score_y8  weighted_score_y9  award_score_y9  \\\n",
      "0                 0.00000            0.00000         0.00000   \n",
      "1                 0.00000            0.00000         0.00000   \n",
      "2                 0.00000          333.85000         0.00000   \n",
      "3                 0.00000          484.60000         0.00000   \n",
      "4                 0.00000            0.00000         0.00000   \n",
      "\n",
      "   post_weighted_score_y9  weighted_score_y10  award_score_y10  \\\n",
      "0                 0.00000             0.00000          0.00000   \n",
      "1                 0.00000             0.00000          0.00000   \n",
      "2                 0.00000           333.10000          0.00000   \n",
      "3                 0.00000           522.75000          0.00000   \n",
      "4                 0.00000             0.00000          0.00000   \n",
      "\n",
      "   post_weighted_score_y10  \n",
      "0                  0.00000  \n",
      "1                  0.00000  \n",
      "2                 22.85000  \n",
      "3                  0.00000  \n",
      "4                  0.00000  \n",
      "     playerID  year tmID  weighted_score_rolling_3  award_score_rolling_3  \\\n",
      "0  adairje01w    11  MIN                   0.00000                0.00000   \n",
      "1  adamsda01w    11  SAS                   0.00000                0.00000   \n",
      "2  ajavoma01w    11  WAS                 222.31667                0.00000   \n",
      "3  anosini01w    11  WAS                 335.78333                0.00000   \n",
      "4  appelja01w    11  SAS                   0.00000                0.00000   \n",
      "\n",
      "   post_weighted_score_rolling_3  \n",
      "0                        0.00000  \n",
      "1                        0.00000  \n",
      "2                        7.61667  \n",
      "3                        0.00000  \n",
      "4                        0.00000  \n"
     ]
    }
   ],
   "execution_count": 218
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T15:10:26.394090Z",
     "start_time": "2024-12-09T15:10:26.392787Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "68962dc65fb6a8",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
